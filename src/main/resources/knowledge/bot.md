# RAG-Try 智能客服知识库

## 技术介绍

### Q: 什么是RAG？
**A:** RAG（Retrieval-Augmented Generation）是检索增强生成技术，它结合了信息检索和文本生成的能力，通过从知识库中检索相关信息来增强大语言模型的回答质量。

### Q: RAG系统的工作原理是什么？
**A:** RAG系统的工作流程包括：1) 将用户问题转换为向量表示；2) 在知识库中检索相似的文档片段；3) 将检索到的信息与原问题一起提供给大语言模型；4) 生成基于知识库的准确回答。

### Q: 什么是Ollama？
**A:** Ollama是一个本地部署大语言模型的工具，支持运行多种开源模型如Llama、Qwen等，提供了embedding和chat功能，适合构建本地RAG系统。

## 系统功能

### Q: 这个系统支持哪些功能？
**A:** 系统主要支持：1) Dify API调用进行智能对话；2) 本地Ollama RAG问答；3) 智能路由机制，自动选择最佳服务；4) 降级机制，确保服务可用性。

### Q: 如何使用Dify功能？
**A:** 通过配置Dify API Key和服务地址，系统可以调用Dify平台的工作流进行智能对话。您只需发送消息，系统会自动转发到Dify并返回回复。

### Q: 如何使用本地RAG功能？
**A:** 本地RAG功能基于Ollama模型，支持向量化检索和语义理解。系统会从知识库中找到最相关的信息，然后生成准确的回答。

## 配置说明

### Q: 如何配置Ollama服务？
**A:** 在application.yml中配置Ollama的服务地址（默认http://localhost:11434）、embedding模型（推荐nomic-embed-text）和chat模型（推荐qwen2:7b）。

### Q: 如何配置Dify API？
**A:** 在application.yml中的dify.api配置项下设置base-url（Dify服务地址）和api-key（您的Dify API密钥）。

### Q: 智能路由策略有哪些？
**A:** 支持三种策略：1) rag-first：优先使用RAG，失败时使用Dify；2) dify-first：优先使用Dify，失败时使用RAG；3) parallel：并行调用，选择最快的回复。

## 使用指南

### Q: 如何开始使用这个系统？
**A:** 1) 确保Java 8+环境；2) 启动Ollama服务并下载所需模型；3) 配置application.yml；4) 运行Spring Boot应用；5) 通过REST API发送请求进行测试。

### Q: 如何添加新的知识？
**A:** 编辑knowledge/bot.md文件，按照"### Q: 问题" "**A:** 答案"的格式添加新的问答对，系统会自动加载新的知识。

### Q: 系统启动失败怎么办？
**A:** 检查：1) Java版本是否正确；2) Ollama服务是否运行；3) 配置文件是否正确；4) 网络连接是否正常；5) 查看日志获取详细错误信息。

## 故障排除

### Q: Ollama连接失败怎么办？
**A:** 检查Ollama服务是否启动（ollama serve），确认服务地址配置正确，检查防火墙设置，确保所需模型已下载。

### Q: Dify API调用失败怎么办？
**A:** 检查API Key是否正确，确认Dify服务地址可访问，检查网络连接，查看API配额是否用完。

### Q: RAG回答不准确怎么办？
**A:** 检查知识库内容是否完整，调整相似度阈值参数，更新embedding模型，增加更多相关的训练数据。

## 性能优化

### Q: 如何提升RAG检索性能？
**A:** 1) 使用更好的embedding模型；2) 调整相似度阈值；3) 启用向量缓存；4) 优化知识库结构；5) 使用更强的硬件配置。

### Q: 如何减少响应时间？
**A:** 1) 启用并行调用策略；2) 配置合理的超时时间；3) 使用本地模型避免网络延迟；4) 优化知识库大小；5) 启用缓存机制。

